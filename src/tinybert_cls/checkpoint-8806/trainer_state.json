{
  "best_global_step": 1887,
  "best_metric": 0.9984089101034208,
  "best_model_checkpoint": "./tinybert_cls\\checkpoint-1887",
  "epoch": 14.0,
  "eval_steps": 500,
  "global_step": 8806,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0794912559618442,
      "grad_norm": 3.053520917892456,
      "learning_rate": 9.974032856385798e-06,
      "loss": 1.1599,
      "step": 50
    },
    {
      "epoch": 0.1589825119236884,
      "grad_norm": 1.6322479248046875,
      "learning_rate": 9.947535771065183e-06,
      "loss": 1.0847,
      "step": 100
    },
    {
      "epoch": 0.2384737678855326,
      "grad_norm": 2.445974349975586,
      "learning_rate": 9.921038685744568e-06,
      "loss": 1.0321,
      "step": 150
    },
    {
      "epoch": 0.3179650238473768,
      "grad_norm": 1.5918306112289429,
      "learning_rate": 9.894541600423955e-06,
      "loss": 0.988,
      "step": 200
    },
    {
      "epoch": 0.397456279809221,
      "grad_norm": 2.7750906944274902,
      "learning_rate": 9.86804451510334e-06,
      "loss": 0.9674,
      "step": 250
    },
    {
      "epoch": 0.4769475357710652,
      "grad_norm": 2.216158866882324,
      "learning_rate": 9.841547429782726e-06,
      "loss": 0.9544,
      "step": 300
    },
    {
      "epoch": 0.5564387917329093,
      "grad_norm": 3.330681800842285,
      "learning_rate": 9.81505034446211e-06,
      "loss": 0.8944,
      "step": 350
    },
    {
      "epoch": 0.6359300476947536,
      "grad_norm": 2.5065369606018066,
      "learning_rate": 9.788553259141495e-06,
      "loss": 0.8637,
      "step": 400
    },
    {
      "epoch": 0.7154213036565977,
      "grad_norm": 2.8271775245666504,
      "learning_rate": 9.76205617382088e-06,
      "loss": 0.7934,
      "step": 450
    },
    {
      "epoch": 0.794912559618442,
      "grad_norm": 2.536858320236206,
      "learning_rate": 9.735559088500266e-06,
      "loss": 0.7737,
      "step": 500
    },
    {
      "epoch": 0.8744038155802861,
      "grad_norm": 4.205373764038086,
      "learning_rate": 9.709062003179651e-06,
      "loss": 0.7461,
      "step": 550
    },
    {
      "epoch": 0.9538950715421304,
      "grad_norm": 2.747253894805908,
      "learning_rate": 9.682564917859036e-06,
      "loss": 0.6844,
      "step": 600
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9204455051710422,
      "eval_loss": 0.5660560727119446,
      "eval_runtime": 0.5869,
      "eval_samples_per_second": 2141.753,
      "eval_steps_per_second": 134.605,
      "step": 629
    },
    {
      "epoch": 1.0333863275039745,
      "grad_norm": 2.9953227043151855,
      "learning_rate": 9.656067832538422e-06,
      "loss": 0.6286,
      "step": 650
    },
    {
      "epoch": 1.1128775834658187,
      "grad_norm": 2.8781564235687256,
      "learning_rate": 9.629570747217807e-06,
      "loss": 0.5933,
      "step": 700
    },
    {
      "epoch": 1.192368839427663,
      "grad_norm": 2.87770414352417,
      "learning_rate": 9.603073661897192e-06,
      "loss": 0.5625,
      "step": 750
    },
    {
      "epoch": 1.2718600953895072,
      "grad_norm": 3.0397374629974365,
      "learning_rate": 9.576576576576578e-06,
      "loss": 0.5194,
      "step": 800
    },
    {
      "epoch": 1.3513513513513513,
      "grad_norm": 2.8709816932678223,
      "learning_rate": 9.550079491255963e-06,
      "loss": 0.49,
      "step": 850
    },
    {
      "epoch": 1.4308426073131955,
      "grad_norm": 2.8979198932647705,
      "learning_rate": 9.523582405935348e-06,
      "loss": 0.4476,
      "step": 900
    },
    {
      "epoch": 1.5103338632750396,
      "grad_norm": 2.3057875633239746,
      "learning_rate": 9.497085320614734e-06,
      "loss": 0.4111,
      "step": 950
    },
    {
      "epoch": 1.589825119236884,
      "grad_norm": 2.1521008014678955,
      "learning_rate": 9.470588235294119e-06,
      "loss": 0.375,
      "step": 1000
    },
    {
      "epoch": 1.669316375198728,
      "grad_norm": 4.695009231567383,
      "learning_rate": 9.444091149973502e-06,
      "loss": 0.3671,
      "step": 1050
    },
    {
      "epoch": 1.7488076311605725,
      "grad_norm": 2.6908488273620605,
      "learning_rate": 9.417594064652888e-06,
      "loss": 0.314,
      "step": 1100
    },
    {
      "epoch": 1.8282988871224166,
      "grad_norm": 4.370779991149902,
      "learning_rate": 9.391096979332273e-06,
      "loss": 0.2895,
      "step": 1150
    },
    {
      "epoch": 1.9077901430842608,
      "grad_norm": 1.6974596977233887,
      "learning_rate": 9.36459989401166e-06,
      "loss": 0.2617,
      "step": 1200
    },
    {
      "epoch": 1.987281399046105,
      "grad_norm": 1.5510141849517822,
      "learning_rate": 9.338102808691046e-06,
      "loss": 0.2383,
      "step": 1250
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9968178202068417,
      "eval_loss": 0.1840798258781433,
      "eval_runtime": 0.6926,
      "eval_samples_per_second": 1814.955,
      "eval_steps_per_second": 114.066,
      "step": 1258
    },
    {
      "epoch": 2.066772655007949,
      "grad_norm": 1.4727535247802734,
      "learning_rate": 9.31160572337043e-06,
      "loss": 0.2262,
      "step": 1300
    },
    {
      "epoch": 2.146263910969793,
      "grad_norm": 1.673287034034729,
      "learning_rate": 9.285108638049816e-06,
      "loss": 0.2038,
      "step": 1350
    },
    {
      "epoch": 2.2257551669316373,
      "grad_norm": 2.1500017642974854,
      "learning_rate": 9.258611552729201e-06,
      "loss": 0.1893,
      "step": 1400
    },
    {
      "epoch": 2.3052464228934815,
      "grad_norm": 1.8168433904647827,
      "learning_rate": 9.232114467408587e-06,
      "loss": 0.1801,
      "step": 1450
    },
    {
      "epoch": 2.384737678855326,
      "grad_norm": 2.05338978767395,
      "learning_rate": 9.20561738208797e-06,
      "loss": 0.1574,
      "step": 1500
    },
    {
      "epoch": 2.46422893481717,
      "grad_norm": 0.923377513885498,
      "learning_rate": 9.179120296767356e-06,
      "loss": 0.1375,
      "step": 1550
    },
    {
      "epoch": 2.5437201907790143,
      "grad_norm": 1.3561798334121704,
      "learning_rate": 9.152623211446741e-06,
      "loss": 0.1382,
      "step": 1600
    },
    {
      "epoch": 2.6232114467408585,
      "grad_norm": 1.0991710424423218,
      "learning_rate": 9.126126126126126e-06,
      "loss": 0.1334,
      "step": 1650
    },
    {
      "epoch": 2.7027027027027026,
      "grad_norm": 1.6328651905059814,
      "learning_rate": 9.099629040805512e-06,
      "loss": 0.1191,
      "step": 1700
    },
    {
      "epoch": 2.7821939586645468,
      "grad_norm": 0.6984712481498718,
      "learning_rate": 9.073131955484897e-06,
      "loss": 0.1087,
      "step": 1750
    },
    {
      "epoch": 2.861685214626391,
      "grad_norm": 0.9089413285255432,
      "learning_rate": 9.046634870164282e-06,
      "loss": 0.1064,
      "step": 1800
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 0.6052132844924927,
      "learning_rate": 9.020137784843668e-06,
      "loss": 0.093,
      "step": 1850
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9984089101034208,
      "eval_loss": 0.07325135171413422,
      "eval_runtime": 0.6604,
      "eval_samples_per_second": 1903.506,
      "eval_steps_per_second": 119.632,
      "step": 1887
    },
    {
      "epoch": 3.0206677265500796,
      "grad_norm": 4.8012261390686035,
      "learning_rate": 8.993640699523053e-06,
      "loss": 0.1009,
      "step": 1900
    },
    {
      "epoch": 3.100158982511924,
      "grad_norm": 0.5782001614570618,
      "learning_rate": 8.967143614202438e-06,
      "loss": 0.1016,
      "step": 1950
    },
    {
      "epoch": 3.179650238473768,
      "grad_norm": 4.375400066375732,
      "learning_rate": 8.940646528881824e-06,
      "loss": 0.076,
      "step": 2000
    },
    {
      "epoch": 3.259141494435612,
      "grad_norm": 0.5461716055870056,
      "learning_rate": 8.914149443561209e-06,
      "loss": 0.0719,
      "step": 2050
    },
    {
      "epoch": 3.338632750397456,
      "grad_norm": 0.508294403553009,
      "learning_rate": 8.887652358240594e-06,
      "loss": 0.0698,
      "step": 2100
    },
    {
      "epoch": 3.4181240063593004,
      "grad_norm": 0.43642458319664,
      "learning_rate": 8.86115527291998e-06,
      "loss": 0.0758,
      "step": 2150
    },
    {
      "epoch": 3.4976152623211445,
      "grad_norm": 2.995919942855835,
      "learning_rate": 8.834658187599365e-06,
      "loss": 0.0619,
      "step": 2200
    },
    {
      "epoch": 3.5771065182829886,
      "grad_norm": 0.4548688530921936,
      "learning_rate": 8.80816110227875e-06,
      "loss": 0.0707,
      "step": 2250
    },
    {
      "epoch": 3.6565977742448332,
      "grad_norm": 0.44222593307495117,
      "learning_rate": 8.781664016958136e-06,
      "loss": 0.0594,
      "step": 2300
    },
    {
      "epoch": 3.7360890302066774,
      "grad_norm": 0.3767077922821045,
      "learning_rate": 8.755166931637521e-06,
      "loss": 0.0638,
      "step": 2350
    },
    {
      "epoch": 3.8155802861685215,
      "grad_norm": 15.140297889709473,
      "learning_rate": 8.728669846316906e-06,
      "loss": 0.0557,
      "step": 2400
    },
    {
      "epoch": 3.8950715421303657,
      "grad_norm": 0.37967175245285034,
      "learning_rate": 8.702172760996292e-06,
      "loss": 0.0568,
      "step": 2450
    },
    {
      "epoch": 3.97456279809221,
      "grad_norm": 0.3568750023841858,
      "learning_rate": 8.675675675675677e-06,
      "loss": 0.0541,
      "step": 2500
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9984089101034208,
      "eval_loss": 0.04254961386322975,
      "eval_runtime": 0.7139,
      "eval_samples_per_second": 1760.804,
      "eval_steps_per_second": 110.663,
      "step": 2516
    },
    {
      "epoch": 4.054054054054054,
      "grad_norm": 0.5284602642059326,
      "learning_rate": 8.649178590355062e-06,
      "loss": 0.0485,
      "step": 2550
    },
    {
      "epoch": 4.133545310015898,
      "grad_norm": 3.138599157333374,
      "learning_rate": 8.622681505034448e-06,
      "loss": 0.0468,
      "step": 2600
    },
    {
      "epoch": 4.213036565977743,
      "grad_norm": 0.3008776903152466,
      "learning_rate": 8.596184419713831e-06,
      "loss": 0.0481,
      "step": 2650
    },
    {
      "epoch": 4.292527821939586,
      "grad_norm": 0.3188983201980591,
      "learning_rate": 8.569687334393217e-06,
      "loss": 0.0492,
      "step": 2700
    },
    {
      "epoch": 4.372019077901431,
      "grad_norm": 2.891667127609253,
      "learning_rate": 8.543190249072602e-06,
      "loss": 0.0441,
      "step": 2750
    },
    {
      "epoch": 4.451510333863275,
      "grad_norm": 0.3264259099960327,
      "learning_rate": 8.516693163751987e-06,
      "loss": 0.0388,
      "step": 2800
    },
    {
      "epoch": 4.531001589825119,
      "grad_norm": 0.29216858744621277,
      "learning_rate": 8.490196078431373e-06,
      "loss": 0.0517,
      "step": 2850
    },
    {
      "epoch": 4.610492845786963,
      "grad_norm": 9.049983978271484,
      "learning_rate": 8.463698993110758e-06,
      "loss": 0.0355,
      "step": 2900
    },
    {
      "epoch": 4.6899841017488075,
      "grad_norm": 0.23606601357460022,
      "learning_rate": 8.437201907790143e-06,
      "loss": 0.0389,
      "step": 2950
    },
    {
      "epoch": 4.769475357710652,
      "grad_norm": 0.2189703732728958,
      "learning_rate": 8.410704822469529e-06,
      "loss": 0.0362,
      "step": 3000
    },
    {
      "epoch": 4.848966613672496,
      "grad_norm": 0.21320459246635437,
      "learning_rate": 8.384207737148914e-06,
      "loss": 0.0441,
      "step": 3050
    },
    {
      "epoch": 4.92845786963434,
      "grad_norm": 0.2993583083152771,
      "learning_rate": 8.3577106518283e-06,
      "loss": 0.0326,
      "step": 3100
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9984089101034208,
      "eval_loss": 0.028881236910820007,
      "eval_runtime": 0.5793,
      "eval_samples_per_second": 2169.846,
      "eval_steps_per_second": 136.371,
      "step": 3145
    },
    {
      "epoch": 5.007949125596184,
      "grad_norm": 0.5907918214797974,
      "learning_rate": 8.331213566507685e-06,
      "loss": 0.0275,
      "step": 3150
    },
    {
      "epoch": 5.087440381558029,
      "grad_norm": 0.1883239448070526,
      "learning_rate": 8.30471648118707e-06,
      "loss": 0.0254,
      "step": 3200
    },
    {
      "epoch": 5.166931637519872,
      "grad_norm": 0.19260947406291962,
      "learning_rate": 8.278219395866455e-06,
      "loss": 0.0321,
      "step": 3250
    },
    {
      "epoch": 5.246422893481717,
      "grad_norm": 0.21993228793144226,
      "learning_rate": 8.25172231054584e-06,
      "loss": 0.0362,
      "step": 3300
    },
    {
      "epoch": 5.325914149443562,
      "grad_norm": 0.28152477741241455,
      "learning_rate": 8.225225225225226e-06,
      "loss": 0.0352,
      "step": 3350
    },
    {
      "epoch": 5.405405405405405,
      "grad_norm": 2.7579421997070312,
      "learning_rate": 8.198728139904611e-06,
      "loss": 0.0349,
      "step": 3400
    },
    {
      "epoch": 5.48489666136725,
      "grad_norm": 0.22426028549671173,
      "learning_rate": 8.172231054583997e-06,
      "loss": 0.0248,
      "step": 3450
    },
    {
      "epoch": 5.5643879173290935,
      "grad_norm": 0.7712429761886597,
      "learning_rate": 8.145733969263382e-06,
      "loss": 0.0269,
      "step": 3500
    },
    {
      "epoch": 5.643879173290938,
      "grad_norm": 2.796506643295288,
      "learning_rate": 8.119236883942767e-06,
      "loss": 0.0305,
      "step": 3550
    },
    {
      "epoch": 5.723370429252782,
      "grad_norm": 0.17589601874351501,
      "learning_rate": 8.092739798622153e-06,
      "loss": 0.0198,
      "step": 3600
    },
    {
      "epoch": 5.802861685214626,
      "grad_norm": 0.1690106838941574,
      "learning_rate": 8.066242713301538e-06,
      "loss": 0.0235,
      "step": 3650
    },
    {
      "epoch": 5.882352941176471,
      "grad_norm": 0.16339974105358124,
      "learning_rate": 8.039745627980923e-06,
      "loss": 0.0256,
      "step": 3700
    },
    {
      "epoch": 5.961844197138315,
      "grad_norm": 0.1521654725074768,
      "learning_rate": 8.013248542660309e-06,
      "loss": 0.0248,
      "step": 3750
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9984089101034208,
      "eval_loss": 0.02131291665136814,
      "eval_runtime": 0.8532,
      "eval_samples_per_second": 1473.356,
      "eval_steps_per_second": 92.598,
      "step": 3774
    },
    {
      "epoch": 6.041335453100159,
      "grad_norm": 0.4187902510166168,
      "learning_rate": 7.986751457339692e-06,
      "loss": 0.0441,
      "step": 3800
    },
    {
      "epoch": 6.120826709062003,
      "grad_norm": 0.1511891782283783,
      "learning_rate": 7.960254372019078e-06,
      "loss": 0.0241,
      "step": 3850
    },
    {
      "epoch": 6.200317965023848,
      "grad_norm": 2.4114487171173096,
      "learning_rate": 7.933757286698463e-06,
      "loss": 0.023,
      "step": 3900
    },
    {
      "epoch": 6.279809220985691,
      "grad_norm": 0.1379043161869049,
      "learning_rate": 7.907260201377848e-06,
      "loss": 0.0191,
      "step": 3950
    },
    {
      "epoch": 6.359300476947536,
      "grad_norm": 0.1511591076850891,
      "learning_rate": 7.880763116057234e-06,
      "loss": 0.0182,
      "step": 4000
    },
    {
      "epoch": 6.43879173290938,
      "grad_norm": 0.13650105893611908,
      "learning_rate": 7.854266030736619e-06,
      "loss": 0.0204,
      "step": 4050
    },
    {
      "epoch": 6.518282988871224,
      "grad_norm": 9.093510627746582,
      "learning_rate": 7.827768945416004e-06,
      "loss": 0.0176,
      "step": 4100
    },
    {
      "epoch": 6.597774244833069,
      "grad_norm": 0.12872794270515442,
      "learning_rate": 7.80127186009539e-06,
      "loss": 0.0276,
      "step": 4150
    },
    {
      "epoch": 6.677265500794912,
      "grad_norm": 0.13057292997837067,
      "learning_rate": 7.774774774774777e-06,
      "loss": 0.0145,
      "step": 4200
    },
    {
      "epoch": 6.756756756756757,
      "grad_norm": 0.10874417424201965,
      "learning_rate": 7.748277689454162e-06,
      "loss": 0.0262,
      "step": 4250
    },
    {
      "epoch": 6.836248012718601,
      "grad_norm": 0.10567139089107513,
      "learning_rate": 7.721780604133546e-06,
      "loss": 0.0214,
      "step": 4300
    },
    {
      "epoch": 6.915739268680445,
      "grad_norm": 0.1405479460954666,
      "learning_rate": 7.695283518812931e-06,
      "loss": 0.0197,
      "step": 4350
    },
    {
      "epoch": 6.995230524642289,
      "grad_norm": 0.12109953165054321,
      "learning_rate": 7.668786433492316e-06,
      "loss": 0.021,
      "step": 4400
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9984089101034208,
      "eval_loss": 0.01805545762181282,
      "eval_runtime": 0.7023,
      "eval_samples_per_second": 1789.922,
      "eval_steps_per_second": 112.493,
      "step": 4403
    },
    {
      "epoch": 7.074721780604134,
      "grad_norm": 0.1037636399269104,
      "learning_rate": 7.642289348171702e-06,
      "loss": 0.0205,
      "step": 4450
    },
    {
      "epoch": 7.154213036565977,
      "grad_norm": 0.09350678324699402,
      "learning_rate": 7.615792262851087e-06,
      "loss": 0.0117,
      "step": 4500
    },
    {
      "epoch": 7.233704292527822,
      "grad_norm": 0.09922066330909729,
      "learning_rate": 7.589295177530472e-06,
      "loss": 0.0184,
      "step": 4550
    },
    {
      "epoch": 7.3131955484896665,
      "grad_norm": 0.1104041039943695,
      "learning_rate": 7.562798092209858e-06,
      "loss": 0.0219,
      "step": 4600
    },
    {
      "epoch": 7.39268680445151,
      "grad_norm": 0.1064569503068924,
      "learning_rate": 7.536301006889243e-06,
      "loss": 0.0184,
      "step": 4650
    },
    {
      "epoch": 7.472178060413355,
      "grad_norm": 0.09072599560022354,
      "learning_rate": 7.509803921568628e-06,
      "loss": 0.011,
      "step": 4700
    },
    {
      "epoch": 7.5516693163751984,
      "grad_norm": 7.347745418548584,
      "learning_rate": 7.483306836248014e-06,
      "loss": 0.0174,
      "step": 4750
    },
    {
      "epoch": 7.631160572337043,
      "grad_norm": 0.08853093534708023,
      "learning_rate": 7.456809750927398e-06,
      "loss": 0.0135,
      "step": 4800
    },
    {
      "epoch": 7.710651828298887,
      "grad_norm": 0.07909965515136719,
      "learning_rate": 7.430312665606783e-06,
      "loss": 0.0117,
      "step": 4850
    },
    {
      "epoch": 7.790143084260731,
      "grad_norm": 0.07512892037630081,
      "learning_rate": 7.403815580286169e-06,
      "loss": 0.0135,
      "step": 4900
    },
    {
      "epoch": 7.869634340222575,
      "grad_norm": 0.19818629324436188,
      "learning_rate": 7.377318494965554e-06,
      "loss": 0.0095,
      "step": 4950
    },
    {
      "epoch": 7.94912559618442,
      "grad_norm": 0.10037305951118469,
      "learning_rate": 7.350821409644939e-06,
      "loss": 0.0159,
      "step": 5000
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9984089101034208,
      "eval_loss": 0.01367733720690012,
      "eval_runtime": 0.653,
      "eval_samples_per_second": 1925.037,
      "eval_steps_per_second": 120.985,
      "step": 5032
    },
    {
      "epoch": 8.028616852146264,
      "grad_norm": 0.06976708769798279,
      "learning_rate": 7.324324324324325e-06,
      "loss": 0.0109,
      "step": 5050
    },
    {
      "epoch": 8.108108108108109,
      "grad_norm": 0.06879466772079468,
      "learning_rate": 7.29782723900371e-06,
      "loss": 0.0089,
      "step": 5100
    },
    {
      "epoch": 8.187599364069952,
      "grad_norm": 2.738443374633789,
      "learning_rate": 7.2713301536830945e-06,
      "loss": 0.0121,
      "step": 5150
    },
    {
      "epoch": 8.267090620031796,
      "grad_norm": 0.0634617954492569,
      "learning_rate": 7.2448330683624816e-06,
      "loss": 0.0177,
      "step": 5200
    },
    {
      "epoch": 8.34658187599364,
      "grad_norm": 0.08266112953424454,
      "learning_rate": 7.218335983041866e-06,
      "loss": 0.0151,
      "step": 5250
    },
    {
      "epoch": 8.426073131955485,
      "grad_norm": 0.06780224293470383,
      "learning_rate": 7.191838897721251e-06,
      "loss": 0.0087,
      "step": 5300
    },
    {
      "epoch": 8.505564387917328,
      "grad_norm": 0.06842491775751114,
      "learning_rate": 7.165341812400637e-06,
      "loss": 0.0104,
      "step": 5350
    },
    {
      "epoch": 8.585055643879173,
      "grad_norm": 0.14069753885269165,
      "learning_rate": 7.138844727080022e-06,
      "loss": 0.0102,
      "step": 5400
    },
    {
      "epoch": 8.664546899841017,
      "grad_norm": 0.15739233791828156,
      "learning_rate": 7.112347641759407e-06,
      "loss": 0.0161,
      "step": 5450
    },
    {
      "epoch": 8.744038155802862,
      "grad_norm": 0.06036674231290817,
      "learning_rate": 7.085850556438793e-06,
      "loss": 0.0075,
      "step": 5500
    },
    {
      "epoch": 8.823529411764707,
      "grad_norm": 0.05801929906010628,
      "learning_rate": 7.059353471118178e-06,
      "loss": 0.007,
      "step": 5550
    },
    {
      "epoch": 8.90302066772655,
      "grad_norm": 0.07917939126491547,
      "learning_rate": 7.0328563857975625e-06,
      "loss": 0.0243,
      "step": 5600
    },
    {
      "epoch": 8.982511923688394,
      "grad_norm": 0.2631557881832123,
      "learning_rate": 7.006359300476948e-06,
      "loss": 0.0197,
      "step": 5650
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9984089101034208,
      "eval_loss": 0.013140515424311161,
      "eval_runtime": 0.5695,
      "eval_samples_per_second": 2207.032,
      "eval_steps_per_second": 138.708,
      "step": 5661
    },
    {
      "epoch": 9.062003179650238,
      "grad_norm": 0.057852599769830704,
      "learning_rate": 6.979862215156333e-06,
      "loss": 0.0107,
      "step": 5700
    },
    {
      "epoch": 9.141494435612083,
      "grad_norm": 0.0476653054356575,
      "learning_rate": 6.9533651298357185e-06,
      "loss": 0.0145,
      "step": 5750
    },
    {
      "epoch": 9.220985691573928,
      "grad_norm": 0.05479397252202034,
      "learning_rate": 6.926868044515104e-06,
      "loss": 0.0103,
      "step": 5800
    },
    {
      "epoch": 9.30047694753577,
      "grad_norm": 0.05256632715463638,
      "learning_rate": 6.900370959194489e-06,
      "loss": 0.0059,
      "step": 5850
    },
    {
      "epoch": 9.379968203497615,
      "grad_norm": 0.05827178806066513,
      "learning_rate": 6.8738738738738745e-06,
      "loss": 0.0063,
      "step": 5900
    },
    {
      "epoch": 9.45945945945946,
      "grad_norm": 0.05133861303329468,
      "learning_rate": 6.847376788553259e-06,
      "loss": 0.0071,
      "step": 5950
    },
    {
      "epoch": 9.538950715421304,
      "grad_norm": 11.467437744140625,
      "learning_rate": 6.820879703232644e-06,
      "loss": 0.0201,
      "step": 6000
    },
    {
      "epoch": 9.618441971383147,
      "grad_norm": 0.047134388238191605,
      "learning_rate": 6.79438261791203e-06,
      "loss": 0.0055,
      "step": 6050
    },
    {
      "epoch": 9.697933227344992,
      "grad_norm": 0.04436700791120529,
      "learning_rate": 6.767885532591415e-06,
      "loss": 0.0186,
      "step": 6100
    },
    {
      "epoch": 9.777424483306836,
      "grad_norm": 0.0505114309489727,
      "learning_rate": 6.7413884472708e-06,
      "loss": 0.0059,
      "step": 6150
    },
    {
      "epoch": 9.85691573926868,
      "grad_norm": 0.04489259794354439,
      "learning_rate": 6.7148913619501865e-06,
      "loss": 0.0148,
      "step": 6200
    },
    {
      "epoch": 9.936406995230525,
      "grad_norm": 0.044749367982149124,
      "learning_rate": 6.688394276629572e-06,
      "loss": 0.0051,
      "step": 6250
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.9984089101034208,
      "eval_loss": 0.01246558129787445,
      "eval_runtime": 0.6786,
      "eval_samples_per_second": 1852.292,
      "eval_steps_per_second": 116.413,
      "step": 6290
    },
    {
      "epoch": 10.015898251192368,
      "grad_norm": 0.0492735356092453,
      "learning_rate": 6.661897191308957e-06,
      "loss": 0.0061,
      "step": 6300
    },
    {
      "epoch": 10.095389507154213,
      "grad_norm": 0.044203776866197586,
      "learning_rate": 6.6354001059883425e-06,
      "loss": 0.0111,
      "step": 6350
    },
    {
      "epoch": 10.174880763116057,
      "grad_norm": 0.9502382278442383,
      "learning_rate": 6.608903020667727e-06,
      "loss": 0.0109,
      "step": 6400
    },
    {
      "epoch": 10.254372019077902,
      "grad_norm": 0.051057931035757065,
      "learning_rate": 6.582405935347112e-06,
      "loss": 0.0084,
      "step": 6450
    },
    {
      "epoch": 10.333863275039745,
      "grad_norm": 0.05048946663737297,
      "learning_rate": 6.555908850026498e-06,
      "loss": 0.0065,
      "step": 6500
    },
    {
      "epoch": 10.41335453100159,
      "grad_norm": 0.036592867225408554,
      "learning_rate": 6.529411764705883e-06,
      "loss": 0.0094,
      "step": 6550
    },
    {
      "epoch": 10.492845786963434,
      "grad_norm": 0.03692609816789627,
      "learning_rate": 6.502914679385268e-06,
      "loss": 0.0119,
      "step": 6600
    },
    {
      "epoch": 10.572337042925279,
      "grad_norm": 0.041415080428123474,
      "learning_rate": 6.476417594064654e-06,
      "loss": 0.0057,
      "step": 6650
    },
    {
      "epoch": 10.651828298887123,
      "grad_norm": 0.04224202781915665,
      "learning_rate": 6.449920508744039e-06,
      "loss": 0.0043,
      "step": 6700
    },
    {
      "epoch": 10.731319554848966,
      "grad_norm": 0.04424342140555382,
      "learning_rate": 6.4234234234234234e-06,
      "loss": 0.0054,
      "step": 6750
    },
    {
      "epoch": 10.81081081081081,
      "grad_norm": 0.03348992392420769,
      "learning_rate": 6.396926338102809e-06,
      "loss": 0.005,
      "step": 6800
    },
    {
      "epoch": 10.890302066772655,
      "grad_norm": 0.05348934978246689,
      "learning_rate": 6.370429252782194e-06,
      "loss": 0.008,
      "step": 6850
    },
    {
      "epoch": 10.9697933227345,
      "grad_norm": 0.04178948700428009,
      "learning_rate": 6.3439321674615794e-06,
      "loss": 0.0041,
      "step": 6900
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.9984089101034208,
      "eval_loss": 0.010298024863004684,
      "eval_runtime": 0.71,
      "eval_samples_per_second": 1770.42,
      "eval_steps_per_second": 111.267,
      "step": 6919
    },
    {
      "epoch": 11.049284578696344,
      "grad_norm": 0.030071411281824112,
      "learning_rate": 6.317435082140965e-06,
      "loss": 0.0038,
      "step": 6950
    },
    {
      "epoch": 11.128775834658187,
      "grad_norm": 0.03376618027687073,
      "learning_rate": 6.29093799682035e-06,
      "loss": 0.0045,
      "step": 7000
    },
    {
      "epoch": 11.208267090620032,
      "grad_norm": 0.08680945634841919,
      "learning_rate": 6.2644409114997354e-06,
      "loss": 0.0079,
      "step": 7050
    },
    {
      "epoch": 11.287758346581876,
      "grad_norm": 0.04716230183839798,
      "learning_rate": 6.23794382617912e-06,
      "loss": 0.009,
      "step": 7100
    },
    {
      "epoch": 11.36724960254372,
      "grad_norm": 0.027609093114733696,
      "learning_rate": 6.211446740858505e-06,
      "loss": 0.007,
      "step": 7150
    },
    {
      "epoch": 11.446740858505564,
      "grad_norm": 0.027293073013424873,
      "learning_rate": 6.184949655537891e-06,
      "loss": 0.0119,
      "step": 7200
    },
    {
      "epoch": 11.526232114467408,
      "grad_norm": 0.25210437178611755,
      "learning_rate": 6.158452570217277e-06,
      "loss": 0.0091,
      "step": 7250
    },
    {
      "epoch": 11.605723370429253,
      "grad_norm": 0.03795388340950012,
      "learning_rate": 6.131955484896662e-06,
      "loss": 0.0131,
      "step": 7300
    },
    {
      "epoch": 11.685214626391097,
      "grad_norm": 0.03155472129583359,
      "learning_rate": 6.105458399576047e-06,
      "loss": 0.0071,
      "step": 7350
    },
    {
      "epoch": 11.764705882352942,
      "grad_norm": 0.03793618083000183,
      "learning_rate": 6.078961314255433e-06,
      "loss": 0.0134,
      "step": 7400
    },
    {
      "epoch": 11.844197138314785,
      "grad_norm": 0.033518314361572266,
      "learning_rate": 6.052464228934818e-06,
      "loss": 0.0096,
      "step": 7450
    },
    {
      "epoch": 11.92368839427663,
      "grad_norm": 20.21796226501465,
      "learning_rate": 6.025967143614203e-06,
      "loss": 0.0078,
      "step": 7500
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.9984089101034208,
      "eval_loss": 0.009167946875095367,
      "eval_runtime": 0.6356,
      "eval_samples_per_second": 1977.668,
      "eval_steps_per_second": 124.293,
      "step": 7548
    },
    {
      "epoch": 12.003179650238474,
      "grad_norm": 0.025851333513855934,
      "learning_rate": 5.999470058293588e-06,
      "loss": 0.0141,
      "step": 7550
    },
    {
      "epoch": 12.082670906200319,
      "grad_norm": 0.0445670448243618,
      "learning_rate": 5.972972972972973e-06,
      "loss": 0.0059,
      "step": 7600
    },
    {
      "epoch": 12.162162162162161,
      "grad_norm": 0.02815582975745201,
      "learning_rate": 5.9464758876523586e-06,
      "loss": 0.0118,
      "step": 7650
    },
    {
      "epoch": 12.241653418124006,
      "grad_norm": 0.030450671911239624,
      "learning_rate": 5.919978802331744e-06,
      "loss": 0.0043,
      "step": 7700
    },
    {
      "epoch": 12.32114467408585,
      "grad_norm": 0.02693074196577072,
      "learning_rate": 5.893481717011129e-06,
      "loss": 0.0028,
      "step": 7750
    },
    {
      "epoch": 12.400635930047695,
      "grad_norm": 0.024341406300663948,
      "learning_rate": 5.8669846316905145e-06,
      "loss": 0.0047,
      "step": 7800
    },
    {
      "epoch": 12.48012718600954,
      "grad_norm": 0.02059413492679596,
      "learning_rate": 5.8404875463699e-06,
      "loss": 0.0115,
      "step": 7850
    },
    {
      "epoch": 12.559618441971383,
      "grad_norm": 0.025650586932897568,
      "learning_rate": 5.813990461049284e-06,
      "loss": 0.0029,
      "step": 7900
    },
    {
      "epoch": 12.639109697933227,
      "grad_norm": 0.02406873181462288,
      "learning_rate": 5.78749337572867e-06,
      "loss": 0.0101,
      "step": 7950
    },
    {
      "epoch": 12.718600953895072,
      "grad_norm": 0.025254083797335625,
      "learning_rate": 5.760996290408055e-06,
      "loss": 0.0028,
      "step": 8000
    },
    {
      "epoch": 12.798092209856916,
      "grad_norm": 0.02176755666732788,
      "learning_rate": 5.73449920508744e-06,
      "loss": 0.0078,
      "step": 8050
    },
    {
      "epoch": 12.87758346581876,
      "grad_norm": 0.13134334981441498,
      "learning_rate": 5.708002119766826e-06,
      "loss": 0.0132,
      "step": 8100
    },
    {
      "epoch": 12.957074721780604,
      "grad_norm": 0.021749824285507202,
      "learning_rate": 5.681505034446212e-06,
      "loss": 0.0098,
      "step": 8150
    },
    {
      "epoch": 13.0,
      "eval_accuracy": 0.9984089101034208,
      "eval_loss": 0.010840489529073238,
      "eval_runtime": 0.5886,
      "eval_samples_per_second": 2135.735,
      "eval_steps_per_second": 134.227,
      "step": 8177
    },
    {
      "epoch": 13.036565977742448,
      "grad_norm": 31.587112426757812,
      "learning_rate": 5.655007949125597e-06,
      "loss": 0.0037,
      "step": 8200
    },
    {
      "epoch": 13.116057233704293,
      "grad_norm": 0.0325356051325798,
      "learning_rate": 5.6285108638049825e-06,
      "loss": 0.0034,
      "step": 8250
    },
    {
      "epoch": 13.195548489666137,
      "grad_norm": 0.01990498974919319,
      "learning_rate": 5.602013778484368e-06,
      "loss": 0.0027,
      "step": 8300
    },
    {
      "epoch": 13.27503974562798,
      "grad_norm": 0.016885356977581978,
      "learning_rate": 5.575516693163753e-06,
      "loss": 0.0048,
      "step": 8350
    },
    {
      "epoch": 13.354531001589825,
      "grad_norm": 0.017644474282860756,
      "learning_rate": 5.549019607843138e-06,
      "loss": 0.0029,
      "step": 8400
    },
    {
      "epoch": 13.43402225755167,
      "grad_norm": 0.021640099585056305,
      "learning_rate": 5.522522522522523e-06,
      "loss": 0.0057,
      "step": 8450
    },
    {
      "epoch": 13.513513513513514,
      "grad_norm": 0.02009880170226097,
      "learning_rate": 5.496025437201908e-06,
      "loss": 0.003,
      "step": 8500
    },
    {
      "epoch": 13.593004769475357,
      "grad_norm": 43.24184799194336,
      "learning_rate": 5.469528351881294e-06,
      "loss": 0.0046,
      "step": 8550
    },
    {
      "epoch": 13.672496025437201,
      "grad_norm": 0.022821802645921707,
      "learning_rate": 5.443031266560679e-06,
      "loss": 0.0023,
      "step": 8600
    },
    {
      "epoch": 13.751987281399046,
      "grad_norm": 0.018328910693526268,
      "learning_rate": 5.416534181240064e-06,
      "loss": 0.0043,
      "step": 8650
    },
    {
      "epoch": 13.83147853736089,
      "grad_norm": 0.02594342827796936,
      "learning_rate": 5.39003709591945e-06,
      "loss": 0.002,
      "step": 8700
    },
    {
      "epoch": 13.910969793322735,
      "grad_norm": 0.03460237756371498,
      "learning_rate": 5.363540010598834e-06,
      "loss": 0.0074,
      "step": 8750
    },
    {
      "epoch": 13.990461049284578,
      "grad_norm": 0.019263166934251785,
      "learning_rate": 5.3370429252782195e-06,
      "loss": 0.002,
      "step": 8800
    },
    {
      "epoch": 14.0,
      "eval_accuracy": 0.9984089101034208,
      "eval_loss": 0.009043003432452679,
      "eval_runtime": 0.6121,
      "eval_samples_per_second": 2053.628,
      "eval_steps_per_second": 129.067,
      "step": 8806
    }
  ],
  "logging_steps": 50,
  "max_steps": 18870,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 30,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 44743353887232.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
