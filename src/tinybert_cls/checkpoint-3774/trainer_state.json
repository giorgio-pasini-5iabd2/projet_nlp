{
  "best_global_step": 1887,
  "best_metric": 0.9984089101034208,
  "best_model_checkpoint": "./tinybert_cls\\checkpoint-1887",
  "epoch": 6.0,
  "eval_steps": 500,
  "global_step": 3774,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0794912559618442,
      "grad_norm": 3.053520917892456,
      "learning_rate": 9.974032856385798e-06,
      "loss": 1.1599,
      "step": 50
    },
    {
      "epoch": 0.1589825119236884,
      "grad_norm": 1.6322479248046875,
      "learning_rate": 9.947535771065183e-06,
      "loss": 1.0847,
      "step": 100
    },
    {
      "epoch": 0.2384737678855326,
      "grad_norm": 2.445974349975586,
      "learning_rate": 9.921038685744568e-06,
      "loss": 1.0321,
      "step": 150
    },
    {
      "epoch": 0.3179650238473768,
      "grad_norm": 1.5918306112289429,
      "learning_rate": 9.894541600423955e-06,
      "loss": 0.988,
      "step": 200
    },
    {
      "epoch": 0.397456279809221,
      "grad_norm": 2.7750906944274902,
      "learning_rate": 9.86804451510334e-06,
      "loss": 0.9674,
      "step": 250
    },
    {
      "epoch": 0.4769475357710652,
      "grad_norm": 2.216158866882324,
      "learning_rate": 9.841547429782726e-06,
      "loss": 0.9544,
      "step": 300
    },
    {
      "epoch": 0.5564387917329093,
      "grad_norm": 3.330681800842285,
      "learning_rate": 9.81505034446211e-06,
      "loss": 0.8944,
      "step": 350
    },
    {
      "epoch": 0.6359300476947536,
      "grad_norm": 2.5065369606018066,
      "learning_rate": 9.788553259141495e-06,
      "loss": 0.8637,
      "step": 400
    },
    {
      "epoch": 0.7154213036565977,
      "grad_norm": 2.8271775245666504,
      "learning_rate": 9.76205617382088e-06,
      "loss": 0.7934,
      "step": 450
    },
    {
      "epoch": 0.794912559618442,
      "grad_norm": 2.536858320236206,
      "learning_rate": 9.735559088500266e-06,
      "loss": 0.7737,
      "step": 500
    },
    {
      "epoch": 0.8744038155802861,
      "grad_norm": 4.205373764038086,
      "learning_rate": 9.709062003179651e-06,
      "loss": 0.7461,
      "step": 550
    },
    {
      "epoch": 0.9538950715421304,
      "grad_norm": 2.747253894805908,
      "learning_rate": 9.682564917859036e-06,
      "loss": 0.6844,
      "step": 600
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9204455051710422,
      "eval_loss": 0.5660560727119446,
      "eval_runtime": 0.5869,
      "eval_samples_per_second": 2141.753,
      "eval_steps_per_second": 134.605,
      "step": 629
    },
    {
      "epoch": 1.0333863275039745,
      "grad_norm": 2.9953227043151855,
      "learning_rate": 9.656067832538422e-06,
      "loss": 0.6286,
      "step": 650
    },
    {
      "epoch": 1.1128775834658187,
      "grad_norm": 2.8781564235687256,
      "learning_rate": 9.629570747217807e-06,
      "loss": 0.5933,
      "step": 700
    },
    {
      "epoch": 1.192368839427663,
      "grad_norm": 2.87770414352417,
      "learning_rate": 9.603073661897192e-06,
      "loss": 0.5625,
      "step": 750
    },
    {
      "epoch": 1.2718600953895072,
      "grad_norm": 3.0397374629974365,
      "learning_rate": 9.576576576576578e-06,
      "loss": 0.5194,
      "step": 800
    },
    {
      "epoch": 1.3513513513513513,
      "grad_norm": 2.8709816932678223,
      "learning_rate": 9.550079491255963e-06,
      "loss": 0.49,
      "step": 850
    },
    {
      "epoch": 1.4308426073131955,
      "grad_norm": 2.8979198932647705,
      "learning_rate": 9.523582405935348e-06,
      "loss": 0.4476,
      "step": 900
    },
    {
      "epoch": 1.5103338632750396,
      "grad_norm": 2.3057875633239746,
      "learning_rate": 9.497085320614734e-06,
      "loss": 0.4111,
      "step": 950
    },
    {
      "epoch": 1.589825119236884,
      "grad_norm": 2.1521008014678955,
      "learning_rate": 9.470588235294119e-06,
      "loss": 0.375,
      "step": 1000
    },
    {
      "epoch": 1.669316375198728,
      "grad_norm": 4.695009231567383,
      "learning_rate": 9.444091149973502e-06,
      "loss": 0.3671,
      "step": 1050
    },
    {
      "epoch": 1.7488076311605725,
      "grad_norm": 2.6908488273620605,
      "learning_rate": 9.417594064652888e-06,
      "loss": 0.314,
      "step": 1100
    },
    {
      "epoch": 1.8282988871224166,
      "grad_norm": 4.370779991149902,
      "learning_rate": 9.391096979332273e-06,
      "loss": 0.2895,
      "step": 1150
    },
    {
      "epoch": 1.9077901430842608,
      "grad_norm": 1.6974596977233887,
      "learning_rate": 9.36459989401166e-06,
      "loss": 0.2617,
      "step": 1200
    },
    {
      "epoch": 1.987281399046105,
      "grad_norm": 1.5510141849517822,
      "learning_rate": 9.338102808691046e-06,
      "loss": 0.2383,
      "step": 1250
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9968178202068417,
      "eval_loss": 0.1840798258781433,
      "eval_runtime": 0.6926,
      "eval_samples_per_second": 1814.955,
      "eval_steps_per_second": 114.066,
      "step": 1258
    },
    {
      "epoch": 2.066772655007949,
      "grad_norm": 1.4727535247802734,
      "learning_rate": 9.31160572337043e-06,
      "loss": 0.2262,
      "step": 1300
    },
    {
      "epoch": 2.146263910969793,
      "grad_norm": 1.673287034034729,
      "learning_rate": 9.285108638049816e-06,
      "loss": 0.2038,
      "step": 1350
    },
    {
      "epoch": 2.2257551669316373,
      "grad_norm": 2.1500017642974854,
      "learning_rate": 9.258611552729201e-06,
      "loss": 0.1893,
      "step": 1400
    },
    {
      "epoch": 2.3052464228934815,
      "grad_norm": 1.8168433904647827,
      "learning_rate": 9.232114467408587e-06,
      "loss": 0.1801,
      "step": 1450
    },
    {
      "epoch": 2.384737678855326,
      "grad_norm": 2.05338978767395,
      "learning_rate": 9.20561738208797e-06,
      "loss": 0.1574,
      "step": 1500
    },
    {
      "epoch": 2.46422893481717,
      "grad_norm": 0.923377513885498,
      "learning_rate": 9.179120296767356e-06,
      "loss": 0.1375,
      "step": 1550
    },
    {
      "epoch": 2.5437201907790143,
      "grad_norm": 1.3561798334121704,
      "learning_rate": 9.152623211446741e-06,
      "loss": 0.1382,
      "step": 1600
    },
    {
      "epoch": 2.6232114467408585,
      "grad_norm": 1.0991710424423218,
      "learning_rate": 9.126126126126126e-06,
      "loss": 0.1334,
      "step": 1650
    },
    {
      "epoch": 2.7027027027027026,
      "grad_norm": 1.6328651905059814,
      "learning_rate": 9.099629040805512e-06,
      "loss": 0.1191,
      "step": 1700
    },
    {
      "epoch": 2.7821939586645468,
      "grad_norm": 0.6984712481498718,
      "learning_rate": 9.073131955484897e-06,
      "loss": 0.1087,
      "step": 1750
    },
    {
      "epoch": 2.861685214626391,
      "grad_norm": 0.9089413285255432,
      "learning_rate": 9.046634870164282e-06,
      "loss": 0.1064,
      "step": 1800
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 0.6052132844924927,
      "learning_rate": 9.020137784843668e-06,
      "loss": 0.093,
      "step": 1850
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9984089101034208,
      "eval_loss": 0.07325135171413422,
      "eval_runtime": 0.6604,
      "eval_samples_per_second": 1903.506,
      "eval_steps_per_second": 119.632,
      "step": 1887
    },
    {
      "epoch": 3.0206677265500796,
      "grad_norm": 4.8012261390686035,
      "learning_rate": 8.993640699523053e-06,
      "loss": 0.1009,
      "step": 1900
    },
    {
      "epoch": 3.100158982511924,
      "grad_norm": 0.5782001614570618,
      "learning_rate": 8.967143614202438e-06,
      "loss": 0.1016,
      "step": 1950
    },
    {
      "epoch": 3.179650238473768,
      "grad_norm": 4.375400066375732,
      "learning_rate": 8.940646528881824e-06,
      "loss": 0.076,
      "step": 2000
    },
    {
      "epoch": 3.259141494435612,
      "grad_norm": 0.5461716055870056,
      "learning_rate": 8.914149443561209e-06,
      "loss": 0.0719,
      "step": 2050
    },
    {
      "epoch": 3.338632750397456,
      "grad_norm": 0.508294403553009,
      "learning_rate": 8.887652358240594e-06,
      "loss": 0.0698,
      "step": 2100
    },
    {
      "epoch": 3.4181240063593004,
      "grad_norm": 0.43642458319664,
      "learning_rate": 8.86115527291998e-06,
      "loss": 0.0758,
      "step": 2150
    },
    {
      "epoch": 3.4976152623211445,
      "grad_norm": 2.995919942855835,
      "learning_rate": 8.834658187599365e-06,
      "loss": 0.0619,
      "step": 2200
    },
    {
      "epoch": 3.5771065182829886,
      "grad_norm": 0.4548688530921936,
      "learning_rate": 8.80816110227875e-06,
      "loss": 0.0707,
      "step": 2250
    },
    {
      "epoch": 3.6565977742448332,
      "grad_norm": 0.44222593307495117,
      "learning_rate": 8.781664016958136e-06,
      "loss": 0.0594,
      "step": 2300
    },
    {
      "epoch": 3.7360890302066774,
      "grad_norm": 0.3767077922821045,
      "learning_rate": 8.755166931637521e-06,
      "loss": 0.0638,
      "step": 2350
    },
    {
      "epoch": 3.8155802861685215,
      "grad_norm": 15.140297889709473,
      "learning_rate": 8.728669846316906e-06,
      "loss": 0.0557,
      "step": 2400
    },
    {
      "epoch": 3.8950715421303657,
      "grad_norm": 0.37967175245285034,
      "learning_rate": 8.702172760996292e-06,
      "loss": 0.0568,
      "step": 2450
    },
    {
      "epoch": 3.97456279809221,
      "grad_norm": 0.3568750023841858,
      "learning_rate": 8.675675675675677e-06,
      "loss": 0.0541,
      "step": 2500
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9984089101034208,
      "eval_loss": 0.04254961386322975,
      "eval_runtime": 0.7139,
      "eval_samples_per_second": 1760.804,
      "eval_steps_per_second": 110.663,
      "step": 2516
    },
    {
      "epoch": 4.054054054054054,
      "grad_norm": 0.5284602642059326,
      "learning_rate": 8.649178590355062e-06,
      "loss": 0.0485,
      "step": 2550
    },
    {
      "epoch": 4.133545310015898,
      "grad_norm": 3.138599157333374,
      "learning_rate": 8.622681505034448e-06,
      "loss": 0.0468,
      "step": 2600
    },
    {
      "epoch": 4.213036565977743,
      "grad_norm": 0.3008776903152466,
      "learning_rate": 8.596184419713831e-06,
      "loss": 0.0481,
      "step": 2650
    },
    {
      "epoch": 4.292527821939586,
      "grad_norm": 0.3188983201980591,
      "learning_rate": 8.569687334393217e-06,
      "loss": 0.0492,
      "step": 2700
    },
    {
      "epoch": 4.372019077901431,
      "grad_norm": 2.891667127609253,
      "learning_rate": 8.543190249072602e-06,
      "loss": 0.0441,
      "step": 2750
    },
    {
      "epoch": 4.451510333863275,
      "grad_norm": 0.3264259099960327,
      "learning_rate": 8.516693163751987e-06,
      "loss": 0.0388,
      "step": 2800
    },
    {
      "epoch": 4.531001589825119,
      "grad_norm": 0.29216858744621277,
      "learning_rate": 8.490196078431373e-06,
      "loss": 0.0517,
      "step": 2850
    },
    {
      "epoch": 4.610492845786963,
      "grad_norm": 9.049983978271484,
      "learning_rate": 8.463698993110758e-06,
      "loss": 0.0355,
      "step": 2900
    },
    {
      "epoch": 4.6899841017488075,
      "grad_norm": 0.23606601357460022,
      "learning_rate": 8.437201907790143e-06,
      "loss": 0.0389,
      "step": 2950
    },
    {
      "epoch": 4.769475357710652,
      "grad_norm": 0.2189703732728958,
      "learning_rate": 8.410704822469529e-06,
      "loss": 0.0362,
      "step": 3000
    },
    {
      "epoch": 4.848966613672496,
      "grad_norm": 0.21320459246635437,
      "learning_rate": 8.384207737148914e-06,
      "loss": 0.0441,
      "step": 3050
    },
    {
      "epoch": 4.92845786963434,
      "grad_norm": 0.2993583083152771,
      "learning_rate": 8.3577106518283e-06,
      "loss": 0.0326,
      "step": 3100
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9984089101034208,
      "eval_loss": 0.028881236910820007,
      "eval_runtime": 0.5793,
      "eval_samples_per_second": 2169.846,
      "eval_steps_per_second": 136.371,
      "step": 3145
    },
    {
      "epoch": 5.007949125596184,
      "grad_norm": 0.5907918214797974,
      "learning_rate": 8.331213566507685e-06,
      "loss": 0.0275,
      "step": 3150
    },
    {
      "epoch": 5.087440381558029,
      "grad_norm": 0.1883239448070526,
      "learning_rate": 8.30471648118707e-06,
      "loss": 0.0254,
      "step": 3200
    },
    {
      "epoch": 5.166931637519872,
      "grad_norm": 0.19260947406291962,
      "learning_rate": 8.278219395866455e-06,
      "loss": 0.0321,
      "step": 3250
    },
    {
      "epoch": 5.246422893481717,
      "grad_norm": 0.21993228793144226,
      "learning_rate": 8.25172231054584e-06,
      "loss": 0.0362,
      "step": 3300
    },
    {
      "epoch": 5.325914149443562,
      "grad_norm": 0.28152477741241455,
      "learning_rate": 8.225225225225226e-06,
      "loss": 0.0352,
      "step": 3350
    },
    {
      "epoch": 5.405405405405405,
      "grad_norm": 2.7579421997070312,
      "learning_rate": 8.198728139904611e-06,
      "loss": 0.0349,
      "step": 3400
    },
    {
      "epoch": 5.48489666136725,
      "grad_norm": 0.22426028549671173,
      "learning_rate": 8.172231054583997e-06,
      "loss": 0.0248,
      "step": 3450
    },
    {
      "epoch": 5.5643879173290935,
      "grad_norm": 0.7712429761886597,
      "learning_rate": 8.145733969263382e-06,
      "loss": 0.0269,
      "step": 3500
    },
    {
      "epoch": 5.643879173290938,
      "grad_norm": 2.796506643295288,
      "learning_rate": 8.119236883942767e-06,
      "loss": 0.0305,
      "step": 3550
    },
    {
      "epoch": 5.723370429252782,
      "grad_norm": 0.17589601874351501,
      "learning_rate": 8.092739798622153e-06,
      "loss": 0.0198,
      "step": 3600
    },
    {
      "epoch": 5.802861685214626,
      "grad_norm": 0.1690106838941574,
      "learning_rate": 8.066242713301538e-06,
      "loss": 0.0235,
      "step": 3650
    },
    {
      "epoch": 5.882352941176471,
      "grad_norm": 0.16339974105358124,
      "learning_rate": 8.039745627980923e-06,
      "loss": 0.0256,
      "step": 3700
    },
    {
      "epoch": 5.961844197138315,
      "grad_norm": 0.1521654725074768,
      "learning_rate": 8.013248542660309e-06,
      "loss": 0.0248,
      "step": 3750
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9984089101034208,
      "eval_loss": 0.02131291665136814,
      "eval_runtime": 0.8532,
      "eval_samples_per_second": 1473.356,
      "eval_steps_per_second": 92.598,
      "step": 3774
    }
  ],
  "logging_steps": 50,
  "max_steps": 18870,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 30,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 19175723094528.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
