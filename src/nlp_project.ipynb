{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee501711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas transformers torch datasets protobuf sentencepiece evaluate scikit-learn evaluate accelerate>=0.26.0 tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fce3162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\giorg\\corsi\\ESGI\\5eme_annee\\NLP\\projet_nlp\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, pipeline\n",
    "import torch\n",
    "from torch import nn\n",
    "from datasets import Dataset, DatasetDict\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import evaluate\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea29394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"votre_token_d_huggingface\")  # Remplacez par votre token Hugging Face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa957aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>intent</th>\n",
       "      <th>category</th>\n",
       "      <th>tags</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I got to add an item to the cart</td>\n",
       "      <td>add_product</td>\n",
       "      <td>CART</td>\n",
       "      <td>BL</td>\n",
       "      <td>I'll get right on it! I'm here to assist you i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wanna add fucking products to the basket can h...</td>\n",
       "      <td>add_product</td>\n",
       "      <td>CART</td>\n",
       "      <td>BCIMQWZ</td>\n",
       "      <td>I sincerely apologize if you've encountered an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i have to add products to the basket i ned help</td>\n",
       "      <td>add_product</td>\n",
       "      <td>CART</td>\n",
       "      <td>BCMQZ</td>\n",
       "      <td>You bet! I'm here to assist you in adding prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>di like to add products to the cart could i ge...</td>\n",
       "      <td>add_product</td>\n",
       "      <td>CART</td>\n",
       "      <td>BCILMPQZ</td>\n",
       "      <td>Indeed! I'm here to assist you in adding produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I need to add an item to the cart , where do I...</td>\n",
       "      <td>add_product</td>\n",
       "      <td>CART</td>\n",
       "      <td>BCILZ</td>\n",
       "      <td>I'll take care of it! I'm here to help you wit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction       intent category  \\\n",
       "0                   I got to add an item to the cart  add_product     CART   \n",
       "1  wanna add fucking products to the basket can h...  add_product     CART   \n",
       "2    i have to add products to the basket i ned help  add_product     CART   \n",
       "3  di like to add products to the cart could i ge...  add_product     CART   \n",
       "4  I need to add an item to the cart , where do I...  add_product     CART   \n",
       "\n",
       "       tags                                           response  \n",
       "0        BL  I'll get right on it! I'm here to assist you i...  \n",
       "1   BCIMQWZ  I sincerely apologize if you've encountered an...  \n",
       "2     BCMQZ  You bet! I'm here to assist you in adding prod...  \n",
       "3  BCILMPQZ  Indeed! I'm here to assist you in adding produ...  \n",
       "4     BCILZ  I'll take care of it! I'm here to help you wit...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/raw/bitext-retail-ecommerce-llm-chatbot-training-dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce29fc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CART', 'PRODUCT', 'ORDER', 'ACCOUNT', 'CONTACT', 'DELIVERY',\n",
       "       'PAYMENT', 'RETURNS', 'USER', 'SALES', 'STORE', 'FEEDBACK',\n",
       "       'APP_WEBSITE'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62626f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "957    i got to see the availability of an item i nee...\n",
       "Name: instruction, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['category'] == 'PRODUCT'].head(1)['instruction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0a7f010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CART', 'PRODUCT', 'ORDER'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# je selectionne uniquement les trois premieres categories\n",
    "small_df = df[df['category'].isin(df['category'].unique()[:3])]\n",
    "small_df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a8d96fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>intent</th>\n",
       "      <th>category</th>\n",
       "      <th>tags</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I got to add an item to the cart</td>\n",
       "      <td>add_product</td>\n",
       "      <td>CART</td>\n",
       "      <td>BL</td>\n",
       "      <td>I'll get right on it! I'm here to assist you i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wanna add fucking products to the basket can h...</td>\n",
       "      <td>add_product</td>\n",
       "      <td>CART</td>\n",
       "      <td>BCIMQWZ</td>\n",
       "      <td>I sincerely apologize if you've encountered an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i have to add products to the basket i ned help</td>\n",
       "      <td>add_product</td>\n",
       "      <td>CART</td>\n",
       "      <td>BCMQZ</td>\n",
       "      <td>You bet! I'm here to assist you in adding prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>di like to add products to the cart could i ge...</td>\n",
       "      <td>add_product</td>\n",
       "      <td>CART</td>\n",
       "      <td>BCILMPQZ</td>\n",
       "      <td>Indeed! I'm here to assist you in adding produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I need to add an item to the cart , where do I...</td>\n",
       "      <td>add_product</td>\n",
       "      <td>CART</td>\n",
       "      <td>BCILZ</td>\n",
       "      <td>I'll take care of it! I'm here to help you wit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction       intent category  \\\n",
       "0                   I got to add an item to the cart  add_product     CART   \n",
       "1  wanna add fucking products to the basket can h...  add_product     CART   \n",
       "2    i have to add products to the basket i ned help  add_product     CART   \n",
       "3  di like to add products to the cart could i ge...  add_product     CART   \n",
       "4  I need to add an item to the cart , where do I...  add_product     CART   \n",
       "\n",
       "       tags                                           response  \n",
       "0        BL  I'll get right on it! I'm here to assist you i...  \n",
       "1   BCIMQWZ  I sincerely apologize if you've encountered an...  \n",
       "2     BCMQZ  You bet! I'm here to assist you in adding prod...  \n",
       "3  BCILMPQZ  Indeed! I'm here to assist you in adding produ...  \n",
       "4     BCILZ  I'll take care of it! I'm here to help you wit...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f335fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I got to add an item to the cart</td>\n",
       "      <td>CART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wanna add fucking products to the basket can h...</td>\n",
       "      <td>CART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i have to add products to the basket i ned help</td>\n",
       "      <td>CART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>di like to add products to the cart could i ge...</td>\n",
       "      <td>CART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I need to add an item to the cart , where do I...</td>\n",
       "      <td>CART</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0                   I got to add an item to the cart  CART\n",
       "1  wanna add fucking products to the basket can h...  CART\n",
       "2    i have to add products to the basket i ned help  CART\n",
       "3  di like to add products to the cart could i ge...  CART\n",
       "4  I need to add an item to the cart , where do I...  CART"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# je mantien que les colonnes instruction et category\n",
    "small_df = small_df[['instruction', 'category']].rename(columns={'instruction': 'text', 'category': 'label'})\n",
    "small_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "997ff24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# je verifie que ma version de CUDA est bien detectee pour utiliser le GPU\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d773e1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'cross-encoder/ms-marco-TinyBERT-L2-v2' # 'meta-llama/Llama-3.2-1B\" #\"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "# Prepare DataFrame: 'text' and 'label' columns\n",
    "dataset = Dataset.from_pandas(small_df)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "num_labels = small_df['label'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6017e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Assume you already have a DataFrame `df` with columns: \"text\" (str) and 'label' (str or int)\n",
    "# Example:\n",
    "# df = pd.read_csv(\"your_data.csv\")  # must contain 'text' and 'label'\n",
    "\n",
    "# Encode string labels to integers if needed\n",
    "if small_df['label'].dtype == \"O\":\n",
    "    le = LabelEncoder()\n",
    "    small_df['label'] = le.fit_transform(small_df['label'])\n",
    "else:\n",
    "    le = None  # labels already numeric\n",
    "\n",
    "num_labels = small_df['label'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b2553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "# # 2. Train/validation split\n",
    "# train_df, val_df = train_test_split(small_df, test_size=0.2, random_state=random_seed, stratify=small_df['label'])\n",
    "\n",
    "# # 3. Convert pandas -> HF Datasets\n",
    "# train_dataset = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "# val_dataset = Dataset.from_pandas(val_df.reset_index(drop=True))\n",
    "# datasets = DatasetDict({\"train\": train_dataset, \"validation\": val_dataset})\n",
    "\n",
    "\n",
    "# First split: train vs temp (test+validation)\n",
    "train_df, t_and_v_df = train_test_split(small_df, random_state=random_seed, test_size=0.2)\n",
    "# Second split: temp -> test vs validation (10% + 10%)\n",
    "test_df, val_df = train_test_split(t_and_v_df, random_state=random_seed, test_size=0.5)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "test_dataset = Dataset.from_pandas(test_df.reset_index(drop=True))\n",
    "val_dataset = Dataset.from_pandas(val_df.reset_index(drop=True))\n",
    "\n",
    "datasets = DatasetDict(\n",
    "    {\n",
    "        \"train\": train_dataset,      # 80%\n",
    "        \"test\": test_dataset,       # 10%\n",
    "        \"val\": val_dataset,  # 10% (held-out final validation)\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4d9be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10059/10059 [00:01<00:00, 8425.96 examples/s]\n",
      "Map: 100%|██████████| 1257/1257 [00:00<00:00, 10130.74 examples/s]\n",
      "Map: 100%|██████████| 1258/1258 [00:00<00:00, 8938.69 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 4. Load TinyBERT tokenizer and model (you can swap to any TinyBERT checkpoint)\n",
    "model_name = \"prajjwal1/bert-tiny\"  # a common TinyBERT-like model on HF Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "    )\n",
    "\n",
    "tokenized_datasets = datasets.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set format for PyTorch\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(\n",
    "    [c for c in tokenized_datasets[\"train\"].column_names if c not in [\"input_ids\", \"attention_mask\", 'label']]\n",
    ")\n",
    "tokenized_datasets.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e279796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Metrics: accuracy and loss will be tracked; we compute accuracy explicitly\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_metric.compute(predictions=preds, references=labels)[\"accuracy\"]\n",
    "    return {\"accuracy\": acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0b1227a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 6. Load TinyBERT with a new classification head sized to num_labels\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    ")\n",
    "\n",
    "# 6a. Print all layers / parameter names before freezing\n",
    "# print(\"Model parameters before freezing:\")\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(name) #print(name, param.shape)\n",
    "\n",
    "\n",
    "# 6b. Freeze all layers except the classification head\n",
    "# for name, param in model.named_parameters():\n",
    "#     # keep only the classifier (and optionally dropout/biases) trainable\n",
    "#     if \"classifier\" in name:\n",
    "#         param.requires_grad = True\n",
    "#     else:\n",
    "#         param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ac78d647",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giorg\\AppData\\Local\\Temp\\ipykernel_26764\\3838270003.py:25: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18870' max='18870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18870/18870 07:38, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.684400</td>\n",
       "      <td>0.566056</td>\n",
       "      <td>0.920446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.238300</td>\n",
       "      <td>0.184080</td>\n",
       "      <td>0.996818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.093000</td>\n",
       "      <td>0.073251</td>\n",
       "      <td>0.998409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.054100</td>\n",
       "      <td>0.042550</td>\n",
       "      <td>0.998409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>0.028881</td>\n",
       "      <td>0.998409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>0.021313</td>\n",
       "      <td>0.998409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.018055</td>\n",
       "      <td>0.998409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.013677</td>\n",
       "      <td>0.998409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>0.013141</td>\n",
       "      <td>0.998409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.012466</td>\n",
       "      <td>0.998409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.010298</td>\n",
       "      <td>0.998409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.009168</td>\n",
       "      <td>0.998409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.010840</td>\n",
       "      <td>0.998409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.009043</td>\n",
       "      <td>0.998409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.011051</td>\n",
       "      <td>0.998409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.007664</td>\n",
       "      <td>0.998409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.008846</td>\n",
       "      <td>0.998409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.008737</td>\n",
       "      <td>0.998409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005004</td>\n",
       "      <td>0.998409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.005614</td>\n",
       "      <td>0.998409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.007273</td>\n",
       "      <td>0.998409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.005205</td>\n",
       "      <td>0.998409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.008906</td>\n",
       "      <td>0.998409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.008008</td>\n",
       "      <td>0.998409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>0.998409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.998409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.002675</td>\n",
       "      <td>0.999204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.005440</td>\n",
       "      <td>0.998409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.005006</td>\n",
       "      <td>0.998409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.004778</td>\n",
       "      <td>0.998409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=18870, training_loss=0.05728635616564978, metrics={'train_runtime': 458.2667, 'train_samples_per_second': 658.503, 'train_steps_per_second': 41.177, 'total_flos': 95878615472640.0, 'train_loss': 0.05728635616564978, 'epoch': 30.0})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "run_name = f\"tinybert_e5_lr1e-5_{run_id}\"\n",
    "\n",
    "# 7. Training configuration\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./tinybert_cls\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=30,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    logging_steps=50,\n",
    "\n",
    "    # >>> TensorBoard-related args <<<\n",
    "    logging_dir=f\"../logs/{run_name}\",   # where TensorBoard will read logs\n",
    "    report_to=[\"tensorboard\"],           # force logging to TensorBoard\n",
    "    run_name=run_name\n",
    ")\n",
    "\n",
    "# 8. Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# 9. Train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "699df4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final validation metrics: {'eval_loss': 0.007263979408890009, 'eval_accuracy': 0.9992050874403816, 'eval_runtime': 1.0204, 'eval_samples_per_second': 1232.884, 'eval_steps_per_second': 77.423, 'epoch': 30.0}\n"
     ]
    }
   ],
   "source": [
    "# final evaluation on the held-out validation set\n",
    "final_metrics = trainer.evaluate(\n",
    "    eval_dataset=tokenized_datasets[\"val\"]\n",
    ")\n",
    "print(\"Final validation metrics:\", final_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8de93326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results: {'eval_loss': 0.0026745139621198177, 'eval_accuracy': 0.9992044550517104, 'eval_runtime': 0.8962, 'eval_samples_per_second': 1402.638, 'eval_steps_per_second': 88.153, 'epoch': 30.0}\n"
     ]
    }
   ],
   "source": [
    "# 10. Final evaluation: accuracy and validation loss\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"Validation results:\", eval_results)\n",
    "# eval_results contains keys like: 'eval_loss', 'eval_accuracy', 'eval_runtime', etc.\n",
    "\n",
    "# 11. Optional: invert label encoding for predictions\n",
    "def predict_texts(texts):\n",
    "    enc = tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**{k: v.to(model.device) for k, v in enc.items()})\n",
    "        preds = outputs.logits.argmax(dim=-1).cpu().numpy()\n",
    "    if le is not None:\n",
    "        preds = le.inverse_transform(preds)\n",
    "    return preds\n",
    "\n",
    "# Example:\n",
    "# print(predict_texts([\"some example text\", \"another text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6fee8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product : I would like to exchange a fucking item I purchased, could I get some help ?\n",
      "product : [{'label': 'LABEL_2', 'score': 0.9998375177383423}]\n",
      "car : I need to add a fucking product to thd cart, can you help me?\n",
      "car : [{'label': 'LABEL_0', 'score': 0.9996371269226074}]\n",
      "ord : I have to track my replacement iitem, could I get some help?\n",
      "ord : [{'label': 'LABEL_1', 'score': 0.9997499585151672}]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/raw/bitext-retail-ecommerce-llm-chatbot-training-dataset.csv')\n",
    "df.head()\n",
    "\n",
    "model_id = \"gpasiniesgi/esgi_nlp_project_1\"  # example HF repo with safetensors weights\n",
    "\n",
    "clf = pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=model_id,\n",
    "    tokenizer=model_id,\n",
    "    # use_safetensors is True by default for modern models, but you can be explicit:\n",
    "    model_kwargs={\"torch_dtype\": \"auto\"},\n",
    ")\n",
    "\n",
    "text_pro = df[df['category'] == 'PRODUCT']['instruction'].sample(n=1).iloc[0]\n",
    "type(text_pro)\n",
    "\n",
    "pred_pro = clf(text_pro)\n",
    "\n",
    "text_car = df[df['category'] == 'CART']['instruction'].sample(n=1).iloc[0]\n",
    "pred_car = clf(text_car)\n",
    "\n",
    "text_ord = df[df['category'] == 'ORDER']['instruction'].sample(n=1).iloc[0]\n",
    "pred_ord = clf(text_ord)\n",
    "\n",
    "print(\"product : \" + text_pro)\n",
    "print(f\"product : {pred_pro}\")\n",
    "\n",
    "print(f'car : {text_car}')\n",
    "print(f'car : {pred_car}')\n",
    "\n",
    "print(f\"ord : {text_ord}\")\n",
    "print(f\"ord : {pred_ord}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
